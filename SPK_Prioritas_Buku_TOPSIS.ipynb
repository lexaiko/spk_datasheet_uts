{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dadadaf",
   "metadata": {},
   "source": [
    "# Sistem Pendukung Keputusan: Prioritas Pengadaan Buku Perpustakaan\n",
    "\n",
    "## Menggunakan Metode TOPSIS (Technique for Order Preference by Similarity to Ideal Solution)\n",
    "\n",
    "**Tujuan:** Menentukan 5 buku yang paling diprioritaskan untuk diadakan/ditambah stoknya berdasarkan multiple criteria decision making.\n",
    "\n",
    "**Dataset:** \n",
    "- Data Buku Perpustakaan.csv\n",
    "- Stok Buku Penerbit.csv  \n",
    "- Usulan Buku.csv\n",
    "\n",
    "**Metode:** TOPSIS (Multi-Attribute Decision Making)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526726e3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style untuk visualisasi\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Library berhasil diimport!\")\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15033887",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f195cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset dari 3 file CSV\n",
    "try:\n",
    "    # Load data buku perpustakaan\n",
    "    df_perpus = pd.read_csv('Data Buku Perpustakaan.csv')\n",
    "    print(\"âœ“ Data Buku Perpustakaan berhasil dimuat\")\n",
    "    print(f\"Shape: {df_perpus.shape}\")\n",
    "    \n",
    "    # Load data stok buku penerbit  \n",
    "    df_penerbit = pd.read_csv('Stok Buku Penerbit.csv')\n",
    "    print(\"âœ“ Stok Buku Penerbit berhasil dimuat\")\n",
    "    print(f\"Shape: {df_penerbit.shape}\")\n",
    "    \n",
    "    # Load data usulan buku\n",
    "    df_usulan = pd.read_csv('Usulan Buku.csv')\n",
    "    print(\"âœ“ Usulan Buku berhasil dimuat\")\n",
    "    print(f\"Shape: {df_usulan.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File tidak ditemukan - {e}\")\n",
    "    print(\"Pastikan file CSV berada di direktori yang sama dengan notebook ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksplorasi struktur data perpustakaan\n",
    "print(\"=== DATA BUKU PERPUSTAKAAN ===\")\n",
    "print(\"\\nKolom:\", df_perpus.columns.tolist())\n",
    "print(\"\\nInfo dataset:\")\n",
    "df_perpus.info()\n",
    "print(\"\\nSample data:\")\n",
    "df_perpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f74152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksplorasi struktur data penerbit\n",
    "print(\"=== DATA STOK BUKU PENERBIT ===\")\n",
    "print(\"\\nKolom:\", df_penerbit.columns.tolist())\n",
    "print(\"\\nInfo dataset:\")\n",
    "df_penerbit.info()\n",
    "print(\"\\nSample data:\")\n",
    "df_penerbit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksplorasi struktur data usulan\n",
    "print(\"=== DATA USULAN BUKU ===\")\n",
    "print(\"\\nKolom:\", df_usulan.columns.tolist())\n",
    "print(\"\\nInfo dataset:\")\n",
    "df_usulan.info()\n",
    "print(\"\\nSample data:\")\n",
    "df_usulan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26ea3a",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Standardisasi kolom ISBN\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Konversi ISBN ke string dan bersihkan\n",
    "df_perpus['ISBN'] = df_perpus['ISBN'].astype(str).str.strip()\n",
    "df_penerbit['ISBN'] = df_penerbit['ISBN'].astype(str).str.strip() \n",
    "df_usulan['ISBN'] = df_usulan['ISBN'].astype(str).str.strip()\n",
    "\n",
    "# Cek duplikasi berdasarkan judul dan ISBN\n",
    "print(\"\\n=== DUPLIKASI CHECK ===\")\n",
    "print(f\"Duplikasi di data perpustakaan (judul): {df_perpus['JUDUL'].duplicated().sum()}\")\n",
    "print(f\"Duplikasi di data penerbit (judul): {df_penerbit['JUDUL'].duplicated().sum()}\")\n",
    "print(f\"Duplikasi di data usulan (judul): {df_usulan['JUDUL'].duplicated().sum()}\")\n",
    "\n",
    "print(f\"Duplikasi di data perpustakaan (ISBN): {df_perpus['ISBN'].duplicated().sum()}\")\n",
    "print(f\"Duplikasi di data penerbit (ISBN): {df_penerbit['ISBN'].duplicated().sum()}\")\n",
    "print(f\"Duplikasi di data usulan (ISBN): {df_usulan['ISBN'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggabungkan data menggunakan pandas merge\n",
    "# Pertama, gabungkan data usulan dengan penerbit berdasarkan ISBN\n",
    "print(\"=== MERGING DATA ===\")\n",
    "\n",
    "# Step 1: Merge usulan dengan penerbit berdasarkan ISBN\n",
    "df_merge_1 = pd.merge(df_usulan, df_penerbit, on='ISBN', how='inner', suffixes=('_usulan', '_penerbit'))\n",
    "print(f\"Hasil merge usulan + penerbit: {df_merge_1.shape[0]} buku\")\n",
    "\n",
    "# Step 2: Coba merge dengan data perpustakaan berdasarkan ISBN\n",
    "df_final = pd.merge(df_merge_1, df_perpus, on='ISBN', how='outer', suffixes=('', '_perpus'))\n",
    "print(f\"Hasil merge final (usulan + penerbit + perpustakaan): {df_final.shape[0]} buku\")\n",
    "\n",
    "# Jika ada konflik kolom, pilih yang lebih relevan\n",
    "# Karena ada beberapa kolom dengan nama sama, kita perlu handle dengan hati-hati\n",
    "print(\"\\nKolom hasil merge:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatif: Merge berdasarkan judul jika ISBN tidak cocok\n",
    "print(\"=== ALTERNATIVE MERGE BERDASARKAN JUDUL ===\")\n",
    "\n",
    "# Standardisasi judul (hapus spasi ekstra, convert ke lowercase untuk matching)\n",
    "df_usulan['JUDUL_CLEAN'] = df_usulan['JUDUL'].str.strip().str.lower()\n",
    "df_penerbit['JUDUL_CLEAN'] = df_penerbit['JUDUL'].str.strip().str.lower()  \n",
    "df_perpus['JUDUL_CLEAN'] = df_perpus['JUDUL'].str.strip().str.lower()\n",
    "\n",
    "# Merge berdasarkan judul yang sudah dibersihkan\n",
    "df_merge_judul = pd.merge(df_usulan, df_penerbit, on='JUDUL_CLEAN', how='inner', suffixes=('_usulan', '_penerbit'))\n",
    "print(f\"Hasil merge usulan + penerbit (berdasarkan judul): {df_merge_judul.shape[0]} buku\")\n",
    "\n",
    "# Cek sample hasil merge\n",
    "print(\"\\nSample hasil merge:\")\n",
    "df_merge_judul[['JUDUL_usulan', 'JUDUL_penerbit', 'JUMLAH USULAN', 'STOK', 'HARGA']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9322f6",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bersihkan dan siapkan data untuk analisis TOPSIS\n",
    "print(\"=== DATA CLEANING ===\")\n",
    "\n",
    "# Gunakan hasil merge berdasarkan judul\n",
    "df_clean = df_merge_judul.copy()\n",
    "\n",
    "# Bersihkan data yang akan digunakan sebagai kriteria\n",
    "# Konversi HARGA ke numeric (handle jika ada format aneh)\n",
    "df_clean['HARGA'] = pd.to_numeric(df_clean['HARGA'], errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Missing values sebelum cleaning:\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Drop rows dengan missing values di kolom penting\n",
    "df_clean = df_clean.dropna(subset=['JUMLAH USULAN', 'STOK', 'HARGA'])\n",
    "\n",
    "# Remove duplicates berdasarkan judul\n",
    "df_clean = df_clean.drop_duplicates(subset=['JUDUL_CLEAN'])\n",
    "\n",
    "# Reset index\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nData setelah cleaning: {df_clean.shape[0]} buku\")\n",
    "print(\"Missing values setelah cleaning:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan kriteria turunan dan persiapan data untuk TOPSIS\n",
    "print(\"=== PERSIAPAN KRITERIA ===\")\n",
    "\n",
    "# Buat kriteria baru berdasarkan tahun terbit (semakin baru semakin baik)\n",
    "df_clean['TAHUN TERBIT_usulan'] = pd.to_numeric(df_clean['TAHUN TERBIT_usulan'], errors='coerce')\n",
    "df_clean['KEBARUAN'] = df_clean['TAHUN TERBIT_usulan']  # Benefit criterion\n",
    "\n",
    "# Filter data yang akan digunakan untuk TOPSIS (minimal harus ada semua kriteria)\n",
    "df_clean = df_clean.dropna(subset=['JUMLAH USULAN', 'STOK', 'HARGA', 'KEBARUAN'])\n",
    "\n",
    "# Buat dataset final untuk TOPSIS\n",
    "columns_needed = ['JUDUL_usulan', 'ISBN_usulan', 'JUMLAH USULAN', 'STOK', 'HARGA', 'KEBARUAN']\n",
    "df_topsis = df_clean[columns_needed].copy()\n",
    "\n",
    "# Rename kolom untuk clarity\n",
    "df_topsis.columns = ['JUDUL', 'ISBN', 'JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN']\n",
    "\n",
    "print(f\"Data siap untuk TOPSIS: {df_topsis.shape[0]} buku\")\n",
    "print(\"\\nSample data:\")\n",
    "df_topsis.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421e701",
   "metadata": {},
   "source": [
    "## 5. Define Criteria and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan kriteria dan bobot untuk TOPSIS\n",
    "print(\"=== DEFINISI KRITERIA DAN BOBOT ===\")\n",
    "\n",
    "# Kriteria yang akan digunakan (minimal 3 kriteria)\n",
    "criteria = {\n",
    "    'JUMLAH_USULAN': {\n",
    "        'type': 'benefit',  # Semakin banyak usulan, semakin prioritas\n",
    "        'weight': 0.35,\n",
    "        'description': 'Jumlah usulan dari user (benefit - semakin banyak semakin baik)'\n",
    "    },\n",
    "    'STOK_PENERBIT': {\n",
    "        'type': 'benefit',  # Semakin banyak stok tersedia, semakin baik\n",
    "        'weight': 0.25, \n",
    "        'description': 'Ketersediaan stok di penerbit (benefit - semakin banyak semakin baik)'\n",
    "    },\n",
    "    'HARGA': {\n",
    "        'type': 'cost',     # Semakin rendah harga, semakin baik\n",
    "        'weight': 0.25,\n",
    "        'description': 'Harga buku (cost - semakin murah semakin baik)'\n",
    "    },\n",
    "    'KEBARUAN': {\n",
    "        'type': 'benefit',  # Semakin baru tahun terbit, semakin baik\n",
    "        'weight': 0.15,\n",
    "        'description': 'Tahun terbit buku (benefit - semakin baru semakin baik)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Validasi bobot (harus total = 1)\n",
    "total_weight = sum([criteria[k]['weight'] for k in criteria.keys()])\n",
    "print(f\"Total bobot: {total_weight}\")\n",
    "\n",
    "if abs(total_weight - 1.0) > 0.001:\n",
    "    print(\"WARNING: Total bobot tidak sama dengan 1!\")\n",
    "else:\n",
    "    print(\"âœ“ Total bobot valid\")\n",
    "\n",
    "# Tampilkan kriteria\n",
    "print(\"\\n=== KRITERIA YANG DIGUNAKAN ===\")\n",
    "for i, (criterion, details) in enumerate(criteria.items(), 1):\n",
    "    print(f\"{i}. {criterion}\")\n",
    "    print(f\"   - Tipe: {details['type'].upper()}\")\n",
    "    print(f\"   - Bobot: {details['weight']}\")\n",
    "    print(f\"   - Deskripsi: {details['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcedbaf",
   "metadata": {},
   "source": [
    "## 6. Implement TOPSIS Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementasi fungsi TOPSIS\n",
    "class TOPSIS:\n",
    "    def __init__(self, decision_matrix, weights, criteria_types):\n",
    "        \"\"\"\n",
    "        decision_matrix: numpy array dengan baris = alternatif, kolom = kriteria\n",
    "        weights: list bobot untuk setiap kriteria\n",
    "        criteria_types: list dengan 'benefit' atau 'cost' untuk setiap kriteria\n",
    "        \"\"\"\n",
    "        self.decision_matrix = np.array(decision_matrix)\n",
    "        self.weights = np.array(weights)\n",
    "        self.criteria_types = criteria_types\n",
    "        self.normalized_matrix = None\n",
    "        self.weighted_matrix = None\n",
    "        self.ideal_best = None\n",
    "        self.ideal_worst = None\n",
    "        self.distances_best = None\n",
    "        self.distances_worst = None\n",
    "        self.scores = None\n",
    "        \n",
    "    def normalize_matrix(self):\n",
    "        \"\"\"Normalisasi matriks menggunakan vector normalization\"\"\"\n",
    "        # Untuk setiap kolom, bagi dengan akar kuadrat dari jumlah kuadrat semua elemen\n",
    "        squared_sums = np.sqrt(np.sum(self.decision_matrix ** 2, axis=0))\n",
    "        self.normalized_matrix = self.decision_matrix / squared_sums\n",
    "        return self.normalized_matrix\n",
    "    \n",
    "    def create_weighted_matrix(self):\n",
    "        \"\"\"Buat weighted normalized matrix\"\"\"\n",
    "        if self.normalized_matrix is None:\n",
    "            self.normalize_matrix()\n",
    "        self.weighted_matrix = self.normalized_matrix * self.weights\n",
    "        return self.weighted_matrix\n",
    "    \n",
    "    def determine_ideal_solutions(self):\n",
    "        \"\"\"Tentukan ideal positive dan negative solution\"\"\"\n",
    "        if self.weighted_matrix is None:\n",
    "            self.create_weighted_matrix()\n",
    "            \n",
    "        self.ideal_best = np.zeros(len(self.criteria_types))\n",
    "        self.ideal_worst = np.zeros(len(self.criteria_types))\n",
    "        \n",
    "        for i, criterion_type in enumerate(self.criteria_types):\n",
    "            if criterion_type == 'benefit':\n",
    "                self.ideal_best[i] = np.max(self.weighted_matrix[:, i])\n",
    "                self.ideal_worst[i] = np.min(self.weighted_matrix[:, i])\n",
    "            else:  # cost\n",
    "                self.ideal_best[i] = np.min(self.weighted_matrix[:, i])\n",
    "                self.ideal_worst[i] = np.max(self.weighted_matrix[:, i])\n",
    "                \n",
    "        return self.ideal_best, self.ideal_worst\n",
    "    \n",
    "    def calculate_distances(self):\n",
    "        \"\"\"Hitung jarak ke ideal positive dan negative solution\"\"\"\n",
    "        if self.ideal_best is None:\n",
    "            self.determine_ideal_solutions()\n",
    "            \n",
    "        # Jarak euclidean ke ideal best dan worst\n",
    "        self.distances_best = np.sqrt(np.sum((self.weighted_matrix - self.ideal_best) ** 2, axis=1))\n",
    "        self.distances_worst = np.sqrt(np.sum((self.weighted_matrix - self.ideal_worst) ** 2, axis=1))\n",
    "        \n",
    "        return self.distances_best, self.distances_worst\n",
    "    \n",
    "    def calculate_scores(self):\n",
    "        \"\"\"Hitung skor TOPSIS (closeness coefficient)\"\"\"\n",
    "        if self.distances_best is None:\n",
    "            self.calculate_distances()\n",
    "            \n",
    "        # Closeness coefficient = d- / (d+ + d-)\n",
    "        self.scores = self.distances_worst / (self.distances_best + self.distances_worst)\n",
    "        return self.scores\n",
    "    \n",
    "    def run_topsis(self):\n",
    "        \"\"\"Jalankan seluruh proses TOPSIS\"\"\"\n",
    "        self.normalize_matrix()\n",
    "        self.create_weighted_matrix()\n",
    "        self.determine_ideal_solutions()\n",
    "        self.calculate_distances()\n",
    "        self.calculate_scores()\n",
    "        return self.scores\n",
    "\n",
    "print(\"âœ“ Class TOPSIS berhasil didefinisikan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea72b67",
   "metadata": {},
   "source": [
    "## 7. Prepare Data for TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapkan data untuk algoritma TOPSIS\n",
    "print(\"=== PERSIAPAN DATA UNTUK TOPSIS ===\")\n",
    "\n",
    "# Ambil kolom kriteria yang akan digunakan\n",
    "criteria_columns = ['JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN']\n",
    "\n",
    "# Buat decision matrix (matriks keputusan)\n",
    "decision_matrix = df_topsis[criteria_columns].values\n",
    "\n",
    "# Siapkan weights dan criteria types\n",
    "weights = [criteria[col]['weight'] for col in criteria_columns]\n",
    "criteria_types = [criteria[col]['type'] for col in criteria_columns]\n",
    "\n",
    "print(f\"Decision matrix shape: {decision_matrix.shape}\")\n",
    "print(f\"Jumlah alternatif (buku): {decision_matrix.shape[0]}\")\n",
    "print(f\"Jumlah kriteria: {decision_matrix.shape[1]}\")\n",
    "\n",
    "print(\"\\nKriteria dan bobotnya:\")\n",
    "for i, col in enumerate(criteria_columns):\n",
    "    print(f\"{i+1}. {col}: {weights[i]} ({criteria_types[i]})\")\n",
    "\n",
    "print(\"\\nSample decision matrix:\")\n",
    "sample_df = pd.DataFrame(decision_matrix[:5], \n",
    "                        columns=criteria_columns,\n",
    "                        index=df_topsis['JUDUL'].iloc[:5])\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b645245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapkan data untuk algoritma TOPSIS\n",
    "print(\"=== PERSIAPAN DATA UNTUK TOPSIS ===\")\n",
    "\n",
    "# Ekstrak matriks keputusan (hanya kolom kriteria)\n",
    "criteria_columns = ['JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN']\n",
    "decision_matrix = df_topsis[criteria_columns].values\n",
    "\n",
    "# Ekstrak bobot dan tipe kriteria\n",
    "weights = [criteria[col]['weight'] for col in criteria_columns]\n",
    "criteria_types = [criteria[col]['type'] for col in criteria_columns]\n",
    "\n",
    "print(\"Matriks keputusan shape:\", decision_matrix.shape)\n",
    "print(\"Jumlah alternatif (buku):\", decision_matrix.shape[0])\n",
    "print(\"Jumlah kriteria:\", decision_matrix.shape[1])\n",
    "\n",
    "print(\"\\nBobot kriteria:\", weights)\n",
    "print(\"Tipe kriteria:\", criteria_types)\n",
    "\n",
    "# Cek ada missing values atau infinity\n",
    "print(f\"\\nMissing values dalam matriks: {np.isnan(decision_matrix).sum()}\")\n",
    "print(f\"Infinity values dalam matriks: {np.isinf(decision_matrix).sum()}\")\n",
    "\n",
    "# Sample matriks keputusan\n",
    "print(\"\\nSample matriks keputusan (5 buku pertama):\")\n",
    "sample_df = pd.DataFrame(decision_matrix[:5], columns=criteria_columns)\n",
    "sample_df.index = df_topsis['JUDUL'].iloc[:5]\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab41da",
   "metadata": {},
   "source": [
    "## 8. Run TOPSIS Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30790cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan algoritma TOPSIS\n",
    "print(\"=== MENJALANKAN ALGORITMA TOPSIS ===\")\n",
    "\n",
    "# Inisialisasi dan jalankan TOPSIS\n",
    "topsis = TOPSIS(decision_matrix, weights, criteria_types)\n",
    "scores = topsis.run_topsis()\n",
    "\n",
    "print(\"âœ“ TOPSIS berhasil dijalankan\")\n",
    "print(f\"âœ“ Scores dihitung untuk {len(scores)} buku\")\n",
    "\n",
    "# Tambahkan skor ke dataframe\n",
    "df_results = df_topsis.copy()\n",
    "df_results['TOPSIS_SCORE'] = scores\n",
    "\n",
    "# Urutkan berdasarkan skor tertinggi\n",
    "df_results = df_results.sort_values('TOPSIS_SCORE', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== TOP 10 BUKU DENGAN SKOR TERTINGGI ===\")\n",
    "top_10 = df_results.head(10)[['JUDUL', 'JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN', 'TOPSIS_SCORE']]\n",
    "for i, row in top_10.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['JUDUL'][:50]:<50} | Score: {row['TOPSIS_SCORE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56225991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan detail proses TOPSIS\n",
    "print(\"=== DETAIL PROSES TOPSIS ===\")\n",
    "\n",
    "print(\"1. Normalized Matrix (5 alternatif pertama):\")\n",
    "normalized_sample = pd.DataFrame(topsis.normalized_matrix[:5], \n",
    "                                columns=criteria_columns,\n",
    "                                index=df_results['JUDUL'].iloc[:5])\n",
    "print(normalized_sample.round(4))\n",
    "\n",
    "print(\"\\n2. Weighted Normalized Matrix (5 alternatif pertama):\")\n",
    "weighted_sample = pd.DataFrame(topsis.weighted_matrix[:5], \n",
    "                              columns=criteria_columns,\n",
    "                              index=df_results['JUDUL'].iloc[:5])\n",
    "print(weighted_sample.round(4))\n",
    "\n",
    "print(\"\\n3. Ideal Solutions:\")\n",
    "ideal_df = pd.DataFrame({\n",
    "    'Positive Ideal Solution (A+)': topsis.ideal_best,\n",
    "    'Negative Ideal Solution (A-)': topsis.ideal_worst\n",
    "}, index=criteria_columns)\n",
    "print(ideal_df.round(4))\n",
    "\n",
    "print(\"\\n4. Distances (5 alternatif teratas):\")\n",
    "distance_df = pd.DataFrame({\n",
    "    'Distance to A+': topsis.distances_best[:5],\n",
    "    'Distance to A-': topsis.distances_worst[:5],\n",
    "    'TOPSIS Score': scores[:5]\n",
    "}, index=df_results['JUDUL'].iloc[:5])\n",
    "print(distance_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832327d9",
   "metadata": {},
   "source": [
    "## 9. Final Results - Top 5 Prioritized Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80169bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HASIL AKHIR: 5 BUKU TERATAS YANG DIPRIORITASKAN\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ† HASIL AKHIR: 5 BUKU YANG PALING DIPRIORITASKAN UNTUK DIADAKAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "top_5_books = df_results.head(5)\n",
    "\n",
    "for i, (idx, book) in enumerate(top_5_books.iterrows(), 1):\n",
    "    print(f\"\\nðŸ“š PERINGKAT {i}\")\n",
    "    print(f\"Judul: {book['JUDUL']}\")\n",
    "    print(f\"ISBN: {book['ISBN']}\")\n",
    "    print(f\"TOPSIS Score: {book['TOPSIS_SCORE']:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"ðŸ“Š Detail Kriteria:\")\n",
    "    print(f\"   â€¢ Jumlah Usulan: {book['JUMLAH_USULAN']} (Bobot: 35%)\")\n",
    "    print(f\"   â€¢ Stok Penerbit: {book['STOK_PENERBIT']} (Bobot: 25%)\")\n",
    "    print(f\"   â€¢ Harga: Rp {book['HARGA']:,.0f} (Bobot: 25%)\")\n",
    "    print(f\"   â€¢ Tahun Terbit: {book['KEBARUAN']:.0f} (Bobot: 15%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“ˆ SUMMARY STATISTIK TOP 5:\")\n",
    "print(\"=\" * 80)\n",
    "summary_stats = top_5_books[['JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN', 'TOPSIS_SCORE']].describe()\n",
    "print(summary_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d314b",
   "metadata": {},
   "source": [
    "## 10. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75355c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi hasil TOPSIS\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Analisis Hasil TOPSIS: Top 5 Buku Prioritas', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Bar chart TOPSIS scores\n",
    "top_10_viz = df_results.head(10)\n",
    "axes[0,0].barh(range(len(top_10_viz)), top_10_viz['TOPSIS_SCORE'], color='skyblue')\n",
    "axes[0,0].set_yticks(range(len(top_10_viz)))\n",
    "axes[0,0].set_yticklabels([title[:30] + '...' if len(title) > 30 else title \n",
    "                          for title in top_10_viz['JUDUL']], fontsize=8)\n",
    "axes[0,0].set_xlabel('TOPSIS Score')\n",
    "axes[0,0].set_title('Top 10 Buku berdasarkan TOPSIS Score')\n",
    "\n",
    "# 2. Scatter plot: Harga vs Jumlah Usulan\n",
    "top_20 = df_results.head(20)\n",
    "scatter = axes[0,1].scatter(top_20['HARGA'], top_20['JUMLAH_USULAN'], \n",
    "                           c=top_20['TOPSIS_SCORE'], cmap='viridis', s=100, alpha=0.7)\n",
    "axes[0,1].set_xlabel('Harga (Rupiah)')  \n",
    "axes[0,1].set_ylabel('Jumlah Usulan')\n",
    "axes[0,1].set_title('Harga vs Jumlah Usulan (Top 20)')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='TOPSIS Score')\n",
    "\n",
    "# 3. Distribution of criteria for top 5\n",
    "top_5_criteria = top_5_books[criteria_columns]\n",
    "axes[1,0].boxplot([top_5_criteria[col] for col in criteria_columns], \n",
    "                  labels=['Usulan', 'Stok', 'Harga', 'Tahun'])\n",
    "axes[1,0].set_title('Distribusi Kriteria - Top 5 Buku')\n",
    "axes[1,0].set_ylabel('Nilai')\n",
    "\n",
    "# 4. Pie chart bobot kriteria\n",
    "axes[1,1].pie(weights, labels=[col.replace('_', ' ') for col in criteria_columns], \n",
    "              autopct='%1.1f%%', startangle=90)\n",
    "axes[1,1].set_title('Bobot Kriteria TOPSIS')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabel perbandingan top 5\n",
    "print(\"\\nðŸ“Š TABEL PERBANDINGAN TOP 5 BUKU:\")\n",
    "display_cols = ['JUDUL', 'JUMLAH_USULAN', 'STOK_PENERBIT', 'HARGA', 'KEBARUAN', 'TOPSIS_SCORE']\n",
    "comparison_table = top_5_books[display_cols].copy()\n",
    "comparison_table['RANKING'] = range(1, 6)\n",
    "comparison_table = comparison_table[['RANKING'] + display_cols]\n",
    "print(comparison_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31fe26",
   "metadata": {},
   "source": [
    "## 11. Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe756a4",
   "metadata": {},
   "source": [
    "### Kesimpulan dan Rekomendasi\n",
    "\n",
    "**Hasil Analisis TOPSIS:**\n",
    "\n",
    "Berdasarkan analisis menggunakan metode TOPSIS (Technique for Order Preference by Similarity to Ideal Solution), telah berhasil ditentukan 5 buku yang paling diprioritaskan untuk diadakan atau ditambah stoknya di perpustakaan.\n",
    "\n",
    "**Kriteria yang Digunakan:**\n",
    "1. **Jumlah Usulan** (35% bobot) - Benefit: Semakin banyak usulan, semakin prioritas\n",
    "2. **Stok Penerbit** (25% bobot) - Benefit: Semakin banyak stok tersedia, semakin mudah pengadaan\n",
    "3. **Harga** (25% bobot) - Cost: Semakin murah, semakin baik untuk anggaran\n",
    "4. **Kebaruan/Tahun Terbit** (15% bobot) - Benefit: Semakin baru, semakin relevan\n",
    "\n",
    "**Keunggulan Metode TOPSIS:**\n",
    "- Mempertimbangkan jarak ke solusi ideal positif dan negatif\n",
    "- Memberikan ranking yang objektif berdasarkan multiple criteria\n",
    "- Dapat menangani kriteria benefit dan cost secara bersamaan\n",
    "- Hasil berupa skor 0-1 yang mudah diinterpretasi\n",
    "\n",
    "**Rekomendasi:**\n",
    "1. Prioritaskan pengadaan 5 buku teratas sesuai hasil analisis\n",
    "2. Pertimbangkan anggaran yang tersedia dengan total estimasi biaya\n",
    "3. Koordinasi dengan penerbit untuk memastikan ketersediaan stok\n",
    "4. Monitor tingkat peminjaman setelah pengadaan untuk evaluasi\n",
    "\n",
    "**Catatan Metodologi:**\n",
    "- Data preprocessing dilakukan dengan menggabungkan 3 dataset terpisah\n",
    "- Normalisasi menggunakan vector normalization\n",
    "- Bobot kriteria dapat disesuaikan sesuai kebijakan perpustakaan"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
